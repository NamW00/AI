{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519dcc00-fc6f-4611-888f-5cd28d0d2d25",
   "metadata": {},
   "source": [
    "> ## **5-2 신경망학습 (4/2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707cd635-e176-4972-b50b-a014ae256a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functions import softmax, cross_entropy_error\n",
    "from numerical_gradient import numerical_gradient_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d463636c-8de6-4e0f-966b-706353b5402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient_2d(f,X):\n",
    "    if X.ndim == 1:\n",
    "        return numerical_gradient_1d(f,X)\n",
    "    else:\n",
    "        grad = np.zeros_like(X) \n",
    "\n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = numerical_gradient_1d(f,x) #행 마다 gradient를 각각 실행시켜준다\n",
    "\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0141f9f4-01f5-4c1b-9e0a-ddc20555ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(3,3)\n",
    "\n",
    "    def predict(self, x):\n",
    "        b = [1] if x.ndim == 1 else np.ones(x.shape[0], 1)\n",
    "        x = np.append(b, x, axis=x.ndim-1)\n",
    "        return np.dot(x, self.W)\n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y,t)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d782d99-ba03-48c2-8b69-66bef99bad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.50338959 -0.02517279  0.37410828]\n",
      " [-0.21652252  0.8138638   1.16338213]\n",
      " [-0.22127259 -0.76564115  0.1110517 ]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5599069c-0e8b-49de-a31e-849e9d736256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.17433074 -0.22593155  1.17208409]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p) # [-1.50844869  1.16179933 -0.99451474] -> 2번 클래스의 predict값이 가장 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb73a52d-30d1-4479-80ce-8afec29dbf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17433074, -0.22593155,  1.17208409])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = np.append([1],x)\n",
    "np.dot(xx, net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e953790a-cb66-4ae5-b1b3-07b83bdb8ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.4798261000025769\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(p)) # 가장 높은 값을 나타내는 index번호\n",
    "t = np.array([0, 0, 1]) # 정답 array는 3번째인 2번 index가 정답\n",
    "print(net.loss(x,t)) # 틀렸으므로 loss값이 큰것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f0c18f-819c-4968-b619-b0c6e18181b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(W):\n",
    "    return net.loss(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c60baaca-e8ad-4a0f-857e-36f4b1624ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22818929  0.15291974 -0.38110903]\n",
      " [ 0.13691357  0.09175184 -0.22866542]\n",
      " [ 0.20537036  0.13762777 -0.34299813]]\n"
     ]
    }
   ],
   "source": [
    "dW = numerical_gradient_2d(f, net.W) # 따라서 손실값을 줄일 수 있도록 gradient를 실행해준다\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed798226-4b47-41dc-a69e-f33559d541aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
